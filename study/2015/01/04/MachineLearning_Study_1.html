<!DOCTYPE html>
<html>
<head>
	<title>Machine Learning Chapter 1</title>
	
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

	<meta name="author" content="hyunjong-lee">

	<meta name="description" content="Home Subscribe Machine Learning Chapter 1 04 Jan 2015 on study --> 04 Jan 2015 on study --> 약 한달간 Pattern Recognition and Machine Learning (이하 PRML) 을 읽고 있는데 1장을 한번 보는데도 꽤 시간이 걸렸습니다. Introduction 챕터인데도 다루는 주제가 광범위하고 깊은 것 같습니다. 저자이신 Bishop 님은 정말 천재의 지니어스인 것 같습니다. 이렇게 방대한 분량을 정리하시다니 -_-; 수학의 정석 이후로 이렇게 정리 잘 되어있는 수학책은 처음봅니다. 인간의 범주를 한참 벗어나신듯. 1장에서 본 주요 키워드 - 대략 60개 -만 나열해보면 다음과 같습니다. 도입하는 챕터라 키워드만 우선 나열하고 추후에 각 챕터에서 집중 공략할 거라고 Bishop 아저씨가 그러셨으니 그러셨을것이라 믿고 일단 주요 키워드만 정리합니다. 틀린 부분이 있으면 알려주세요 &gt;_&lt;! Keywords training set: 모델의 파라메터 학습을 위해 훈련에 사용하는 데이터 test set: 훈련된 파라메터가..." />

	<meta http-equiv="date" content="Sunday, 04  2015 15:23:00 GMT" />

	<meta name="keywords" content="" />

	<meta name="robots" content="INDEX,FOLLOW" />
	
    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <!-- Customisation  -->
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />

    <link rel="stylesheet" type="text/css" href="/assets/css/prism.css" />

</head>
<body class="post-template">

    <header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        <a class="back-button icon-arrow-left" href="/">Home</a>
        <a class="subscribe-button icon-feed" href="/rss.xml">Subscribe</a>
    </nav>
</header>

<main class="content" role="main">

    <article class="post">

        <header class="post-header">
            <h1 class="post-title">Machine Learning Chapter 1</h1>
            <section class="post-meta">                
                <time class="post-date" datetime="2015-01-04">04 Jan 2015</time>
                 
                    on study 
                
            </section>
        </header>

<!--         <header class="post-header">
            <a id="blog-logo" href="http://hyunjong-lee.github.io">
                
                    <img src="true" alt="Human Learning" />
                 
            </a>
        </header> -->
        
        <!-- <span class="post-meta">
            <time datetime="2015-01-04">04 Jan 2015</time>
             
                on study 
            
        </span> -->

        <!-- <h1 class="post-title">Machine Learning Chapter 1</h1> -->

        <section class="post-content">
            <p>약 한달간 <a href="http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738">Pattern Recognition and Machine Learning</a> (이하 PRML) 을 읽고 있는데 1장을 한번 보는데도 꽤 시간이 걸렸습니다.
Introduction 챕터인데도 다루는 주제가 광범위하고 깊은 것 같습니다. 저자이신 <a href="http://en.wikipedia.org/wiki/Christopher_Bishop">Bishop</a> 님은 정말 천재의 지니어스인 것 같습니다.
이렇게 방대한 분량을 정리하시다니 -_-; 수학의 정석 이후로 이렇게 정리 잘 되어있는 수학책은 처음봅니다. 인간의 범주를 한참 벗어나신듯.</p>

<p>1장에서 본 <strong>주요 키워드 - 대략 60개 -</strong>만 나열해보면 다음과 같습니다.
도입하는 챕터라 키워드만 우선 나열하고 추후에 각 챕터에서 집중 공략할 거라고 <a href="http://en.wikipedia.org/wiki/Christopher_Bishop">Bishop</a> 아저씨가 그러셨으니 그러셨을것이라 믿고 일단 주요 키워드만 정리합니다.
틀린 부분이 있으면 알려주세요 &gt;_&lt;!</p>

<h2 id="keywords">Keywords</h2>

<ul>
  <li><strong>training set</strong>: 모델의 파라메터 학습을 위해 훈련에 사용하는 데이터</li>
  <li><strong>test set</strong>: 훈련된 파라메터가 올바른지 테스트 하기 위해 사용하는 데이터</li>
  <li><strong>feature extraction</strong>: preprocessing 단계이며 주어진 데이터를 다른 공간으로 변형시키는 걸 의미</li>
</ul>

<h3 id="supervised-learning">Supervised Learning</h3>

<ul>
  <li>training set과 그에 대응하는 목표값도 같이 알 경우 <a href="http://ko.wikipedia.org/wiki/%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5">지도 학습</a> 방법을 적용</li>
  <li><strong>classification</strong>: 유한한 갯수의 class에 대해서 주어진 데이터가 어떤 class에 속하는지 예측하는 것을 classification problem이라 부름</li>
  <li><strong>regression</strong>: 실수와 같이 유한한 클래스로 제한할 수 없는 데이터에 대해 예측하는 것을 regression problem이라 부름</li>
</ul>

<h3 id="unsupervised-learning">Unsupervised Learning</h3>

<ul>
  <li>training set이 주어져 있지만 대응하는 목표값이 주어지지 않을 때 <a href="http://ko.wikipedia.org/wiki/%EC%9E%90%EC%9C%A8_%ED%95%99%EC%8A%B5_(%EA%B8%B0%EA%B3%84_%ED%95%99%EC%8A%B5)">자율 학습</a> 방법을 적용</li>
  <li><strong>clustering</strong>: 비슷한 특징을 보이는 데이터를 그룹화</li>
  <li><strong>density estimation</strong>: 데이터의 분포를 파악</li>
</ul>

<h3 id="reinforcement-learning">Reinforcement Learning</h3>

<ul>
  <li><a href="http://ko.wikipedia.org/wiki/%EA%B0%95%ED%99%94_%ED%95%99%EC%8A%B5">강화 학습</a>은 주어진 환경에서 어떤 행동을 취해야 보상을 최대화 할 수 있을지 찾아내는 방법</li>
  <li>에이전트가 어떤 행위를 하였을 때 그에 대응하는 보상의 피드백으로 최적화 된 행동을 찾아가는 학습 방법, 하지만 이 책은 다루지 않는다!</li>
</ul>

<h3 id="polynomial-curve-fitting">Polynomial Curve Fitting</h3>

<ul>
  <li>다항식을 활용하여 주어진 데이터를 어떻게 해석할 수 있는지 설명하는 것으로 본격적인 챕터 시작!</li>
  <li>목표는 매우 간단함: <strong>새로운 데이터가 주어졌을 때 예측을 잘할 수 있도록 일반화를 잘하자</strong></li>
  <li><strong>random noise</strong>: 데이터가 임의의 노이즈로 인해 변형이 생겼을 것으로 가정, 해당 챕터에서는 random noise가 Gaussian distribution분포를 갖고 있다고 가정한 후 training set 생성</li>
  <li><strong>polynomial function</strong>: 익히 알고 있는 선형함수, 아래의 형태를 갖고 있음</li>
</ul>

<script type="math/tex; mode=display">
\begin{align*}
 y(x, \mathbf{w}) = w_{0} + w_{1}x + + w_{2}x^2 + \ldots + w_{M}x^M = \sum_{j=0}^{M}{w_{j}x^{j}}
\end{align*}
</script>

<script type="math/tex; mode=display">
\begin{align*}
 \mathbf{w} = \left\{w_{0}, w_{1}, w_{2}, \ldots, w_{M}\right\}
\end{align*}
</script>

<ul>
  <li><strong>linear model</strong>: 위 다항식에서 모르는 파라메터 값은 <strong>w</strong>인데 이와 같은 형태를 선형모델이라고 부름 - x가 고차원인 것은 상관없음</li>
  <li><strong>error function</strong>: training set으로 학습한 모델이 목표치와 얼마나 다른지 나타내는 함수</li>
  <li><strong>RMSE (root-mean-square-error)</strong>: 대표적인 error function 중 하나, 우항의 1/2은 추후 편의를 위해 임의로 추가한 값, 목표값과 추정한 값의 차이에 대해 제곱한 값의 합</li>
</ul>

<script type="math/tex; mode=display">
\begin{align*}
 E(\mathbf{w}) = \frac{1}{2} \sum_{n=1}^{N}\left\{y(x_{n}, \mathbf{w}) - t_{n}\right\}^2
\end{align*}
</script>

<ul>
  <li>model complexity</li>
  <li>over-fitting
    <ul>
      <li>학습 데이터에 대해서만 최적화 된 상태로 새로운 데이터에 대해선 예측이 잘 안되는 상태를 말함</li>
      <li>모델이 복잡한데 비해 학습 데이터가 부족할 경우 발생할 가능성이 높음</li>
    </ul>
  </li>
  <li>maximum likelihood</li>
  <li>Bayesian approach, Bayesian model</li>
  <li>Regularization
    <ul>
      <li>위에서 언급한 over-fitting을 방지하는 방법 중 하나</li>
    </ul>
  </li>
  <li>shrinkage</li>
  <li>ridge regression, weight decay</li>
  <li>validation set, hold-out set</li>
</ul>

<h3 id="probability-theory">Probability Theory</h3>

<ul>
  <li>The Rules of Probability</li>
</ul>

<dl>
  <dt>sum rule</dt>
  <dd><script type="math/tex"> p(X) = \sum_{Y} p(X, Y) </script></dd>
  <dt>product rule</dt>
  <dd><script type="math/tex"> p(X, Y) = p(Y \mid X) p(X) </script></dd>
</dl>

<script type="math/tex; mode=display">
\begin{align*}
 posterior \propto likelihood \times prior
\end{align*}
</script>

<ul>
  <li>앞면/뒷면으로 이루어진 동전 하나를 던진다고 할 때 아래와 같이 해석 가능
    <ul>
      <li><strong>prior</strong>: 앞면/뒷면이 나타날 확률에 대해 사전에 알고 있는 정보 (앞면/뒷면의 확률은 5:5)</li>
      <li><strong>likelihood</strong>: 실험을 통해 앞면/뒷면이 나타난 분포에 대한 정보</li>
      <li><strong>posterior</strong>: 사전에 알고 있던 분포에 실험을 통해 나타난 분포를 결합하여 나타난 분포</li>
    </ul>
  </li>
  <li>Gaussian distribution</li>
  <li>Bayesian curve fitting</li>
</ul>

<h3 id="model-selection">Model Selection</h3>

<ul>
  <li>validation set</li>
  <li>cross-validation</li>
  <li>leave-one-out</li>
  <li>information criteria</li>
  <li>AIC (Akaike information criteria)</li>
  <li>BIC (Bayesian information criteria)</li>
</ul>

<h3 id="the-curse-of-dimensionality">The Curse of Dimensionality</h3>

<h3 id="decision-theory">Decision Theory</h3>

<ul>
  <li>decision boundaries, decision surfaces</li>
  <li>loss function, cost function</li>
  <li>loss matrix</li>
  <li>reject option</li>
  <li>inference stage, decision stage</li>
  <li>discriminant function</li>
  <li>three distinct approaches to solving decision problem</li>
  <li>generative models: solve inference problem for each class individually + infer prior class probabilities, then use Bayes’ theorem</li>
  <li>discriminative models: solve inference problem of posterior class probabilities directly</li>
  <li>find a function f(X), called a discriminant function</li>
  <li>outlier detection, novelty detection</li>
  <li>naive Bayes model</li>
</ul>

<h3 id="information-theory">Information Theory</h3>

<ul>
  <li>entropy</li>
  <li>noiseless coding theorem</li>
  <li>multiplicity</li>
  <li>microstate, macrostate</li>
  <li>Lagrange multiplier</li>
  <li>mean value theorem</li>
  <li>differential entropy</li>
  <li>conditional entropy</li>
  <li>KL divergence, Kullback-Leibler divergence, relative entropy</li>
  <li>convex function, convexity</li>
  <li>strictly convex</li>
  <li>concave</li>
  <li>strictly concave</li>
  <li>Jensen’s inequality</li>
  <li>mutual information</li>
</ul>


        </section>

        

        <footer class="post-footer">
            <!-- If we want to display author's name and bio -->
            
                <figure class="author-image">
                    <a class="img" href="/" style="background-image: url(/assets/images/profile.png)">
                    <span class="hidden">Hyunjong's Picture</span></a>
                </figure>
                <section class="author">
                    <!-- Author Name -->
                    <h4> Hyunjong </h4>
                    <!-- Author Bio -->
                    <p> 
                        I am a software developer. Interested in problem solving & machine learning.
                    </p>
                </section>                
            

            <!-- Share links section -->
            <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?text=Machine Learning Chapter 1&amp;url=http://hyunjong-lee.github.io/study/2015/01/04/MachineLearning_Study_1.html"
        onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://hyunjong-lee.github.io/study/2015/01/04/MachineLearning_Study_1.html"
        onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=http://hyunjong-lee.github.io/study/2015/01/04/MachineLearning_Study_1.html"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
            
            <!-- Disqus comments -->
            
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">

        var disqus_shortname = 'humanleaning'; 
        var disqus_developer = 0; // developer mode is on
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            
            
        </footer>

    </article>

</main>

    <footer class="site-footer clearfix">
      <section class="copyright">
        <a href="/">Human Learning</a> &copy; 
               &bull; All rights reserved.
      </section>
      <section class="poweredby">Made with Jekyll using 
        <a href="http://github.com/rosario/kasper">Kasper theme</a>
      </section>
    </footer>
    
    <script type="text/javascript" src="/assets/js/prism.js"></script>
    <script type="text/javascript" src="/assets/js/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/assets/js/index.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- Google Analytics Tracking code -->
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-54954001-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>

</body>
</html>
